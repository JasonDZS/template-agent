#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æŠ¥å‘Šç”Ÿæˆå™¨ä¸»æ¨¡å—
æ•´åˆAgentã€å·¥å…·å’Œè½¬æ¢å™¨åŠŸèƒ½
"""

import asyncio
import argparse
from pathlib import Path
from typing import Optional

from app.agent.report_multi import ReportGeneratorAgent
from app.tool.knowledge_retrieval import get_knowledge_retrieval_tool
from app.converter import MarkdownConverter, ConversionRequest
from app.logger import logger
from app.config import settings

# TaskScheduler imports
from app.template.task_scheduler import TaskScheduler
from app.template.task_executors import TaskExecutor, TaskInput, TaskOutput
from app.template.task_models import Task, TaskType, TaskStatus
from app.agent.section_agent import SectionAgent
from app.agent.merge_agent import MergeAgent
from app.template import MarkdownTaskSchedule


class SectionAgentExecutor(TaskExecutor):
    """Task executor that uses SectionAgent for content generation"""
    
    def __init__(self, knowledge_base_path: str = "workdir/documents", **kwargs):
        super().__init__(**kwargs)
        self.knowledge_base_path = knowledge_base_path
    
    def can_execute(self, task: Task) -> bool:
        """Check if this executor can handle generation tasks"""
        return task.task_type == TaskType.GENERATION
    
    async def execute(self, task_input: TaskInput) -> TaskOutput:
        """Execute generation task using SectionAgent"""
        task = task_input.task
        
        # Log input details
        self.log_task_input(task_input)
        
        try:
            # Create section info for SectionAgent following tutorial format
            section_info = {
                "id": task.id,
                "content": task.title,
                "level": task.level,
                "description": f"Generate content for section: {task.title}"
            }
            
            # Create report context
            report_context = {
                "title": task_input.context.get("report_title", "Report"),
                "type": task_input.context.get("report_type", "document")
            }
            logger.info(f"ğŸ”§ Starting SectionAgent for: {task.title}")
            logger.info(f"   Section ID: {task.id}, Level: {task.level}")
            logger.info(f"   Knowledge base: {self.knowledge_base_path}")
            # Create and run SectionAgent with proper parameters
            agent = SectionAgent(
                section_info=section_info,
                report_context=report_context,
                output_format=task.section_content,
                knowledge_base_path=self.knowledge_base_path
            )
            
            await agent.run()
            
            if agent.is_finished():
                agent_content = content = agent.get_content()
                if not content:
                    content = f"[Generation failed] {task.title}: No content generated"
                    logger.warning(f"âš ï¸ SectionAgent generated empty content for {task.title}")
                else:
                    logger.info(f"âœ… SectionAgent completed successfully for {task.title}")
                    logger.info(f"   Generated content length: {len(content)} characters")
            else:
                agent_content = content = f"[Generation incomplete] {task.title}: Agent did not finish successfully"
                logger.warning(f"âš ï¸ SectionAgent did not complete for {task.title}")

            # Add section header if not already present
            if not content.startswith('#'):
                content = "#" * task.level + " " + task.title + "\n" + content
            else:
                # Ensure proper heading level
                lines = content.split('\n', 1)
                if lines[0].startswith('#'):
                    # Replace existing heading with proper level
                    header = "#" * task.level + " " + task.title
                    content = header + ("\n" + lines[1] if len(lines) > 1 else "")

            task_output = TaskOutput(
                content=content,
                metadata={
                    "task_type": "generation",
                    "agent_type": "SectionAgent",
                    "section_title": task.title,
                    "section_level": task.level,
                    "content_length": len(content),
                    "executor_id": self.executor_id,
                    "agent_content": agent_content,
                    "memory": agent.memory.messages if hasattr(agent, 'memory') else []
                }
            )
            
            # Log output details
            self.log_task_output(task, task_output)
            
            return task_output
            
        except Exception as e:
            self.log_task_error(task, e)
            logger.error(f"âŒ SectionAgent execution failed for {task.title}: {str(e)}")
            # Return error content instead of raising exception
            error_content = f"[Generation Error] {task.title}: {str(e)}"
            return TaskOutput(
                content=error_content,
                metadata={
                    "task_type": "generation",
                    "error": str(e),
                    "error_type": type(e).__name__,
                    "executor_id": self.executor_id,
                    "section_title": task.title,
                    "section_level": task.level
                }
            )


class MergeAgentExecutor(TaskExecutor):
    """Task executor that uses MergeAgent for content merging"""
    
    def __init__(self, knowledge_base_path: str = "workdir/documents", **kwargs):
        super().__init__(**kwargs)
        self.knowledge_base_path = knowledge_base_path
    
    def can_execute(self, task: Task) -> bool:
        """Check if this executor can handle merge tasks"""
        return task.task_type == TaskType.MERGE
    
    async def execute(self, task_input: TaskInput) -> TaskOutput:
        """Execute merge task using MergeAgent"""
        task = task_input.task
        
        # Log input details
        self.log_task_input(task_input)
        
        try:
            # Create section info for MergeAgent following tutorial format  
            section_info = {
                "id": task.id,
                "content": task.title,
                "level": task.level,
                "description": f"Merge content for section: {task.title}"
            }
            
            # Create report context
            report_context = {
                "title": task_input.context.get("report_title", "Report"),
                "type": task_input.context.get("report_type", "document")
            }
            
            # Get child contents from dependencies
            child_contents = list(task_input.dependencies_content.values())
            
            logger.info(f"ğŸ”€ Starting MergeAgent for: {task.title}")
            logger.info(f"   Section ID: {task.id}, Level: {task.level}")
            logger.info(f"   Merging {len(child_contents)} child contents")
            logger.info(f"   Expected dependencies: {len(task.dependencies)}, Received: {len(task_input.dependencies_content)}")
            
            if not child_contents:
                agent_content = content = f"[Merge Warning] {task.title}: No child contents to merge"
                memory = []
                logger.warning(f"âš ï¸ No child contents available for merging {task.title}")
            else:
                # Create and run MergeAgent (remove knowledge_base_path as it's not supported)
                agent = MergeAgent(
                    section_info=section_info,
                    report_context=report_context,
                    child_contents=child_contents,
                    output_format=task.section_content if hasattr(task, 'section_content') else None
                )
                
                await agent.run()
                
                if agent.is_finished():
                    agent_content = content = agent.get_content()
                    memory = agent.memory.messages if hasattr(agent, 'memory') else []
                    
                    if not content:
                        content = f"[Merge failed] {task.title}: No content generated"
                        logger.warning(f"âš ï¸ MergeAgent generated empty content for {task.title}")
                    else:
                        logger.info(f"âœ… MergeAgent completed successfully for {task.title}")
                        logger.info(f"   Merged content length: {len(content)} characters")
                        logger.info(f"   Successfully merged {len(child_contents)} child contents")
                else:
                    agent_content = content = f"[Merge incomplete] {task.title}: Agent did not finish successfully"
                    memory = []
                    logger.warning(f"âš ï¸ MergeAgent did not complete for {task.title}")

            # Add section header if not already present (for merge tasks)
            if not content.startswith('#'):
                content = "#" * task.level + " " + task.title + "\n" + content
            else:
                # Ensure proper heading level
                lines = content.split('\n', 1)
                if lines[0].startswith('#'):
                    # Replace existing heading with proper level
                    header = "#" * task.level + " " + task.title
                    content = header + ("\n" + lines[1] if len(lines) > 1 else "")

            task_output = TaskOutput(
                content=content,
                metadata={
                    "task_type": "merge",
                    "agent_type": "MergeAgent",
                    "section_title": task.title,
                    "section_level": task.level,
                    "child_count": len(child_contents),
                    "expected_dependencies": len(task.dependencies),
                    "received_dependencies": len(task_input.dependencies_content),
                    "content_length": len(content),
                    "executor_id": self.executor_id,
                    "agent_content": agent_content,
                    "memory": memory
                }
            )
            
            # Log output details
            self.log_task_output(task, task_output)
            
            return task_output
            
        except Exception as e:
            self.log_task_error(task, e)
            logger.error(f"âŒ MergeAgent execution failed for {task.title}: {str(e)}")
            # Return error content instead of raising exception
            error_content = f"[Merge Error] {task.title}: {str(e)}"
            return TaskOutput(
                content=error_content,
                metadata={
                    "task_type": "merge",
                    "error": str(e),
                    "error_type": type(e).__name__,
                    "executor_id": self.executor_id,
                    "section_title": task.title,
                    "section_level": task.level,
                    "child_count": len(child_contents) if 'child_contents' in locals() else 0
                }
            )


class ReportGenerationSystem:
    """æŠ¥å‘Šç”Ÿæˆç³»ç»Ÿ"""

    def __init__(self,
                 knowledge_base_path: str = "workdir/documents",
                 template_base_path: str = "workdir/template"):
        self.knowledge_base_path = Path(knowledge_base_path)
        self.template_base_path = Path(template_base_path)
        self.converter = MarkdownConverter()

        # ç¡®ä¿ç›®å½•å­˜åœ¨
        self.knowledge_base_path.mkdir(parents = True, exist_ok = True)
        self.template_base_path.mkdir(parents = True, exist_ok = True)

    async def generate_report(self,
                              template_name: str,
                              output_name: Optional[str] = None,
                              max_steps: int = 20,
                              use_schedule: bool = False,
                              confirm_execution: bool = True) -> str:
        """ç”ŸæˆæŠ¥å‘Š"""
        try:
            # æŸ¥æ‰¾æ¨¡æ¿æ–‡ä»¶
            template_path = self._find_template(template_name)
            if not template_path:
                raise FileNotFoundError(f"æœªæ‰¾åˆ°æ¨¡æ¿æ–‡ä»¶: {template_name}")

            # è®¾ç½®è¾“å‡ºè·¯å¾„
            if not output_name:
                output_name = f"generated_report_{template_path.stem}"

            output_path = Path("workdir") / "output" / output_name
            output_path.parent.mkdir(parents = True, exist_ok = True)

            # åˆ›å»ºå¹¶é…ç½®Agent
            agent = ReportGeneratorAgent(
                name = f"report_generator_{template_path.stem}",
                description = f"åŸºäºæ¨¡æ¿ {template_path.name} ç”ŸæˆæŠ¥å‘Š",
                template_path = str(template_path),
                knowledge_base_path = str(self.knowledge_base_path),
                output_path = str(output_path),
                max_steps = max_steps,
                parallel_sections = settings.parallel_sections,
                max_concurrent = settings.max_concurrent,
            )

            logger.info(f"å¼€å§‹ç”ŸæˆæŠ¥å‘Šï¼Œæ¨¡æ¿: {template_path.name}")
            logger.info(f"çŸ¥è¯†åº“è·¯å¾„: {self.knowledge_base_path}")
            logger.info(f"è¾“å‡ºè·¯å¾„: {output_path}")
            logger.info(f"ä½¿ç”¨è°ƒåº¦æ¨¡å¼: {use_schedule}")

            # è¿è¡ŒAgent
            if use_schedule:
                result = await self._run_with_task_scheduler(
                    str(template_path), 
                    str(output_path),
                    max_steps,
                    confirm_execution
                )
                # è·å–è¿›åº¦ä¿¡æ¯ï¼ˆä»schedulerä¸­è·å–ï¼‰
                return result
            else:
                result = await agent.run_with_template(str(template_path), str(output_path))

            # è·å–è¿›åº¦ä¿¡æ¯
            progress = agent.get_progress()

            success_message = f"""æŠ¥å‘Šç”Ÿæˆå®Œæˆï¼

æ¨¡æ¿: {template_path.name}
è¿›åº¦: {progress['completed_sections']}/{progress['total_sections']} 
      ({progress['progress_percentage']:.1f}%)
è¾“å‡º: {output_path}.json, {output_path}.md

è¯¦ç»†æ‰§è¡Œç»“æœ:
{result}"""

            logger.info("æŠ¥å‘Šç”Ÿæˆä»»åŠ¡å®Œæˆ")
            return success_message

        except Exception as e:
            error_message = f"æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {str(e)}"
            logger.error(error_message)
            raise Exception(error_message)

    def _find_template(self, template_name: str) -> Optional[Path]:
        """æŸ¥æ‰¾æ¨¡æ¿æ–‡ä»¶"""
        # ç›´æ¥è·¯å¾„
        if Path(template_name).exists():
            return Path(template_name)

        # åœ¨æ¨¡æ¿ç›®å½•ä¸­æŸ¥æ‰¾
        possible_paths = [
            self.template_base_path / template_name,
            self.template_base_path / f"{template_name}.md",
            self.template_base_path / f"{template_name}.json"
        ]

        for path in possible_paths:
            if path.exists():
                return path

        return None

    async def _run_with_task_scheduler(self, template_path: str, output_path: str, 
                                       max_steps: int, confirm_execution: bool) -> str:
        """ä½¿ç”¨TaskSchedulerè¿è¡Œå·¥ä½œæµç¨‹"""
        try:
            logger.info(f"å¼€å§‹ä½¿ç”¨TaskScheduleræ‰§è¡Œå·¥ä½œæµç¨‹")
            logger.info(f"æ¨¡æ¿è·¯å¾„: {template_path}")
            logger.info(f"è¾“å‡ºè·¯å¾„: {output_path}")
            logger.info(f"æœ€å¤§å¹¶å‘: {settings.max_concurrent}")
            
            # Check template file exists
            if not Path(template_path).exists():
                raise FileNotFoundError(f"æ¨¡æ¿æ–‡ä»¶ä¸å­˜åœ¨: {template_path}")
            
            # Load template and create task schedule
            schedule = MarkdownTaskSchedule(template_path, max_concurrent=settings.max_concurrent)
            
            # Get task information
            graph_info = schedule.get_task_graph_info()
            logger.info(f"ä»»åŠ¡ç»Ÿè®¡ä¿¡æ¯:")
            logger.info(f"   æ€»ä»»åŠ¡æ•°: {graph_info['total_tasks']}")
            logger.info(f"   ç”Ÿæˆä»»åŠ¡: {graph_info['generation_tasks']}")
            logger.info(f"   åˆå¹¶ä»»åŠ¡: {graph_info['merge_tasks']}")
            logger.info(f"   æœ€å¤§ä¾èµ–æ·±åº¦: {graph_info.get('max_dependency_depth', 0)}")
            
            if graph_info['total_tasks'] == 0:
                raise ValueError("æ¨¡æ¿ä¸­æœªæ‰¾åˆ°ä»»åŠ¡")
            
            # Ask for user confirmation if needed
            if confirm_execution:
                print(f"\nğŸ“‹ ä»»åŠ¡é˜Ÿåˆ—ä¿¡æ¯:")
                print(f"   æ€»ä»»åŠ¡æ•°: {graph_info['total_tasks']}")
                print(f"   ç”Ÿæˆä»»åŠ¡: {graph_info['generation_tasks']}")
                print(f"   åˆå¹¶ä»»åŠ¡: {graph_info['merge_tasks']}")
                print(f"   æœ€å¤§å¹¶å‘: {settings.max_concurrent}")
                
                user_input = input("\næ˜¯å¦ç»§ç»­æ‰§è¡Œ? (y/N): ").strip().lower()
                if user_input not in ['y', 'yes', 'æ˜¯']:
                    return "ç”¨æˆ·å–æ¶ˆäº†ä»»åŠ¡æ‰§è¡Œ"
            
            # Create task scheduler
            scheduler = TaskScheduler(max_concurrent=settings.max_concurrent)
            
            # Register executors with detected knowledge base path
            section_executor = SectionAgentExecutor(
                knowledge_base_path=str(self.knowledge_base_path),
                executor_id="section_executor_1"
            )
            merge_executor = MergeAgentExecutor(
                executor_id="merge_executor_1"
            )
            
            scheduler.register_executor(section_executor)
            scheduler.register_executor(merge_executor)
            
            # Set global context for all executors
            template_name = Path(template_path).stem
            scheduler.set_global_context({
                "report_title": f"åŸºäº{template_name}çš„æŠ¥å‘Š",
                "report_type": "template_generated",
                "template_path": template_path
            })
            
            # Add all tasks to scheduler
            for task in schedule.tasks.values():
                scheduler.add_task(task)
            
            logger.info(f"å¼€å§‹ä»»åŠ¡æ‰§è¡Œ...")
            logger.info(f"   æœ€å¤§å¹¶å‘: {settings.max_concurrent}")
            logger.info(f"   æ€»ä»»åŠ¡æ•°: {len(schedule.tasks)}")
            
            # Execute tasks in rounds
            round_num = 1
            max_rounds = min(max_steps, 20)  # Safety limit
            
            while round_num <= max_rounds:
                # Get ready tasks
                ready_tasks = scheduler.get_ready_tasks()
                
                if not ready_tasks:
                    # Check if all tasks are completed
                    progress = scheduler.get_progress()
                    if progress["completed_tasks"] + progress["failed_tasks"] == progress["total_tasks"]:
                        logger.info(f"æ‰€æœ‰ä»»åŠ¡å·²å®Œæˆ!")
                        break
                    else:
                        logger.warning(f"æ²¡æœ‰å°±ç»ªä»»åŠ¡ä½†æ‰§è¡Œæœªå®Œæˆ - å¯èƒ½å­˜åœ¨å¾ªç¯ä¾èµ–")
                        break
                
                # Limit concurrent tasks
                available_slots = scheduler.max_concurrent - len(scheduler.running_tasks)
                tasks_to_execute = ready_tasks[:available_slots]
                
                logger.info(f"ç¬¬{round_num}è½®: æ‰§è¡Œ{len(tasks_to_execute)}ä¸ªä»»åŠ¡")
                for task in tasks_to_execute:
                    icon = "ğŸ”§" if task.task_type == TaskType.GENERATION else "ğŸ”€"
                    logger.info(f"   {icon} {task.title} (Level {task.level})")
                
                # Execute tasks concurrently
                execution_tasks = []
                for task in tasks_to_execute:
                    execution_tasks.append(scheduler.execute_task(task))
                
                # Wait for completion
                if execution_tasks:
                    await asyncio.gather(*execution_tasks, return_exceptions=True)
                
                # Show progress
                progress = scheduler.get_progress()
                logger.info(f"   è¿›åº¦: {progress['completed_tasks']}/{progress['total_tasks']} å·²å®Œæˆ")
                logger.info(f"   æˆåŠŸç‡: {progress['success_rate']:.1f}%")
                
                round_num += 1
                
                # Short delay between rounds
                await asyncio.sleep(0.1)
            
            # Final statistics
            progress = scheduler.get_progress()
            logger.info(f"æœ€ç»ˆç»Ÿè®¡:")
            logger.info(f"   æ€»ä»»åŠ¡æ•°: {progress['total_tasks']}")
            logger.info(f"   å·²å®Œæˆ: {progress['completed_tasks']}")
            logger.info(f"   å¤±è´¥: {progress['failed_tasks']}")
            logger.info(f"   æˆåŠŸç‡: {progress['success_rate']:.1f}%")
            logger.info(f"   æ‰§è¡Œè½®æ¬¡: {round_num - 1}")
            
            # Generate final report
            final_report_path = await self._generate_final_report(scheduler, template_path, output_path)
            
            success_message = f"""TaskScheduleræŠ¥å‘Šç”Ÿæˆå®Œæˆï¼

æ¨¡æ¿: {Path(template_path).name}
è¿›åº¦: {progress['completed_tasks']}/{progress['total_tasks']} 
      ({progress['success_rate']:.1f}%)
è¾“å‡º: {final_report_path}
æ‰§è¡Œè½®æ¬¡: {round_num - 1}

è¯¦ç»†æ‰§è¡Œç»“æœ:
- æ€»ä»»åŠ¡æ•°: {progress['total_tasks']}
- å·²å®Œæˆ: {progress['completed_tasks']}
- å¤±è´¥: {progress['failed_tasks']}
- æˆåŠŸç‡: {progress['success_rate']:.1f}%"""

            return success_message
            
        except Exception as e:
            error_message = f"TaskSchedulerå·¥ä½œæµç¨‹æ‰§è¡Œå¤±è´¥: {str(e)}"
            logger.error(error_message)
            raise Exception(error_message)

    async def _generate_final_report(self, scheduler: TaskScheduler, template_path: str, output_path: str) -> str:
        """ä»ä»»åŠ¡ç»“æœç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š"""
        logger.info(f"ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š...")
        
        # Get all task results
        task_results = scheduler.get_task_results()
        
        if not task_results:
            logger.warning("æ²¡æœ‰å¯ç”¨çš„ä»»åŠ¡ç»“æœ")
            return None
        
        # Extract heading node line number for proper ordering
        def extract_line_number(task_obj):
            try:
                heading_node = task_obj.heading_node
                if hasattr(heading_node, 'attributes') and heading_node.attributes:
                    line_num = heading_node.attributes.get('line_number', 0)
                    return line_num
                return 0
            except (AttributeError, KeyError):
                return 0
        
        # Find root tasks (tasks with no dependents) and sort by document order
        all_dependencies = set()
        for task in scheduler.tasks.values():
            all_dependencies.update(task.dependencies)
        
        # Collect only root tasks with results
        root_tasks = []
        for task_id, task in scheduler.tasks.items():
            if (task_id not in all_dependencies and 
                task.result and task.result.content):
                root_tasks.append((task, task.result))
        
        logger.info(f"æ‰¾åˆ°{len(root_tasks)}ä¸ªæ ¹çº§ä»»åŠ¡å¹¶æœ‰å†…å®¹")
        if len(root_tasks) == 0:
            logger.warning("æ²¡æœ‰æ‰¾åˆ°æ ¹çº§ä»»åŠ¡ä¸”æœ‰å†…å®¹çš„!")
            # Debug: show all task statuses
            status_summary = {}
            for task in scheduler.tasks.values():
                status = str(task.status)
                status_summary[status] = status_summary.get(status, 0) + 1
            logger.info(f"ä»»åŠ¡çŠ¶æ€æ‘˜è¦: {status_summary}")
            return None
        
        # Sort root tasks by level first, then by document order (line number)
        root_tasks.sort(key=lambda x: (x[0].level, extract_line_number(x[0])))
        
        # Build final report
        template_name = Path(template_path).stem
        final_report = ""

        # Add content with proper structure
        for task, result in root_tasks:
            # The content from agents already includes proper headings, just add it directly
            content = result.content.strip()
            if content:
                final_report += f"{content}\n\n"
        
        # Save report as markdown
        output_md_path = f"{output_path}.md"
        Path(output_md_path).parent.mkdir(parents=True, exist_ok=True)
        
        with open(output_md_path, 'w', encoding='utf-8') as f:
            f.write(final_report)
        
        # Also save detailed task results as JSON
        output_json_path = f"{output_path}.json"
        import json
        detailed_results = {}
        for task, result in root_tasks:
            # Clean metadata to remove non-serializable objects
            clean_metadata = {}
            for key, value in result.metadata.items():
                if key == "memory":
                    # Convert memory messages to serializable format
                    if value and isinstance(value, list):
                        clean_metadata[key] = [
                            {
                                "role": getattr(msg, 'role', 'unknown'),
                                "content": str(getattr(msg, 'content', ''))
                            } for msg in value
                        ]
                    else:
                        clean_metadata[key] = []
                else:
                    try:
                        json.dumps(value)  # Test if value is JSON serializable
                        clean_metadata[key] = value
                    except (TypeError, ValueError):
                        clean_metadata[key] = str(value)  # Convert to string if not serializable
            
            detailed_results[task.id] = {
                "title": task.title,
                "level": task.level,
                "task_type": task.task_type.value,
                "status": task.status.value,
                "content": result.content,
                "metadata": clean_metadata
            }
        
        with open(output_json_path, 'w', encoding='utf-8') as f:
            json.dump(detailed_results, f, ensure_ascii=False, indent=2)
        
        logger.info(f"æœ€ç»ˆæŠ¥å‘Šå·²ä¿å­˜: {output_md_path}")
        logger.info(f"è¯¦ç»†ç»“æœå·²ä¿å­˜: {output_json_path}")
        logger.info(f"æŠ¥å‘Šé•¿åº¦: {len(final_report)} å­—ç¬¦")
        
        return output_md_path

    async def convert_template(self,
                               template_path: str,
                               output_format: str = "json") -> str:
        """è½¬æ¢æ¨¡æ¿æ ¼å¼"""
        try:
            template_file = Path(template_path)
            if not template_file.exists():
                raise FileNotFoundError(f"æ¨¡æ¿æ–‡ä»¶ä¸å­˜åœ¨: {template_path}")

            # è¯»å–æ¨¡æ¿å†…å®¹
            template_content = template_file.read_text(encoding = 'utf-8')

            # ç¡®å®šæºæ ¼å¼
            source_format = "markdown" if template_content.strip().startswith('#') else "json"

            # æ‰§è¡Œè½¬æ¢
            conversion_request = ConversionRequest(
                source_format = source_format,
                target_format = output_format,
                content = template_content
            )

            result = self.converter.convert(conversion_request)

            if result.success:
                # ä¿å­˜è½¬æ¢ç»“æœ
                output_path = template_file.with_suffix(f'.{output_format}')
                if output_format == "json":
                    import json
                    with open(output_path, 'w', encoding = 'utf-8') as f:
                        json.dump(result.result, f, ensure_ascii = False, indent = 2)
                else:
                    with open(output_path, 'w', encoding = 'utf-8') as f:
                        f.write(result.result)

                return f"æ¨¡æ¿è½¬æ¢æˆåŠŸ: {output_path}"
            else:
                raise Exception(result.error)

        except Exception as e:
            error_message = f"æ¨¡æ¿è½¬æ¢å¤±è´¥: {str(e)}"
            logger.error(error_message)
            raise Exception(error_message)

    async def test_knowledge_base(self, query: str = "æ™ºèƒ½é‹å«") -> str:
        """æµ‹è¯•çŸ¥è¯†åº“æ£€ç´¢"""
        try:
            knowledge_tool = get_knowledge_retrieval_tool(str(self.knowledge_base_path))
            result = await knowledge_tool.execute(query = query, threshold=settings.distance, top_k = settings.top_k)

            if result.error:
                return f"çŸ¥è¯†åº“æ£€ç´¢æµ‹è¯•å¤±è´¥: {result.error}"
            else:
                stats = knowledge_tool.get_statistics()
                return f"""çŸ¥è¯†åº“æ£€ç´¢æµ‹è¯•æˆåŠŸï¼

ç»Ÿè®¡ä¿¡æ¯:
- æ–‡æ¡£æ€»æ•°: {stats['total_documents']}
- æ€»å¤§å°: {stats['total_size']} å­—ç¬¦
- å¹³å‡å¤§å°: {stats['average_size']} å­—ç¬¦
- æ–‡ä»¶ç±»å‹: {stats['file_types']}

æ£€ç´¢ç»“æœ (æŸ¥è¯¢: "{query}"):
{result.output}"""

        except Exception as e:
            error_message = f"çŸ¥è¯†åº“æµ‹è¯•å¤±è´¥: {str(e)}"
            logger.error(error_message)
            return error_message

    def list_templates(self) -> str:
        """åˆ—å‡ºå¯ç”¨æ¨¡æ¿"""
        templates = []

        if self.template_base_path.exists():
            for file_path in self.template_base_path.iterdir():
                if file_path.is_file() and file_path.suffix in ['.md', '.json']:
                    templates.append({
                        "name": file_path.name,
                        "path": str(file_path),
                        "size": file_path.stat().st_size,
                        "type": file_path.suffix[1:]
                    })

        if not templates:
            return "æœªæ‰¾åˆ°å¯ç”¨æ¨¡æ¿"

        result = "å¯ç”¨æ¨¡æ¿:\n"
        for i, template in enumerate(templates, 1):
            result += f"{i}. {template['name']} ({template['type']}, {template['size']} bytes)\n"

        return result


async def main():
    """å‘½ä»¤è¡Œå…¥å£"""
    parser = argparse.ArgumentParser(description = "æ™ºèƒ½æŠ¥å‘Šç”Ÿæˆå™¨")
    parser.add_argument("action", choices = ["generate", "convert", "test", "list"],
                        help = "æ‰§è¡Œçš„æ“ä½œ")
    parser.add_argument("--template", "-t", help = "æ¨¡æ¿åç§°æˆ–è·¯å¾„")
    parser.add_argument("--output", "-o", help = "è¾“å‡ºæ–‡ä»¶å")
    parser.add_argument("--format", "-f", default = "json",
                        choices = ["json", "markdown"], help = "è½¬æ¢ç›®æ ‡æ ¼å¼")
    parser.add_argument("--query", "-q", default = "æ™ºèƒ½é‹å«", help = "æµ‹è¯•æŸ¥è¯¢")
    parser.add_argument("--max-steps", type = int, default = 200, help = "æœ€å¤§æ‰§è¡Œæ­¥æ•°")
    parser.add_argument("--knowledge-base", default = "workdir/documents",
                        help = "çŸ¥è¯†åº“è·¯å¾„")
    parser.add_argument("--template-base", default = "workdir/template",
                        help = "æ¨¡æ¿åŸºç¡€è·¯å¾„")
    parser.add_argument("--schedule", action="store_true", 
                        help = "ä½¿ç”¨ä»»åŠ¡è°ƒåº¦æ¨¡å¼")
    parser.add_argument("--no-confirm", action="store_true",
                        help = "è·³è¿‡ç”¨æˆ·ç¡®è®¤ï¼ˆè‡ªåŠ¨æ‰§è¡Œï¼‰")

    args = parser.parse_args()

    # åˆ›å»ºæŠ¥å‘Šç”Ÿæˆç³»ç»Ÿ
    system = ReportGenerationSystem(
        knowledge_base_path = args.knowledge_base,
        template_base_path = args.template_base
    )

    try:
        if args.action == "generate":
            if not args.template:
                print("é”™è¯¯: ç”ŸæˆæŠ¥å‘Šéœ€è¦æŒ‡å®šæ¨¡æ¿ (--template)")
                return

            result = await system.generate_report(
                template_name = args.template,
                output_name = args.output,
                max_steps = args.max_steps,
                use_schedule = args.schedule,
                confirm_execution = not args.no_confirm
            )
            print(result)

        elif args.action == "convert":
            if not args.template:
                print("é”™è¯¯: è½¬æ¢æ¨¡æ¿éœ€è¦æŒ‡å®šæ¨¡æ¿è·¯å¾„ (--template)")
                return

            result = await system.convert_template(
                template_path = args.template,
                output_format = args.format
            )
            print(result)

        elif args.action == "test":
            result = await system.test_knowledge_base(query = args.query)
            print(result)

        elif args.action == "list":
            result = system.list_templates()
            print(result)

    except Exception as e:
        print(f"æ‰§è¡Œå¤±è´¥: {e}")
        logger.error(f"å‘½ä»¤æ‰§è¡Œå¤±è´¥: {e}")


if __name__ == "__main__":
    asyncio.run(main())